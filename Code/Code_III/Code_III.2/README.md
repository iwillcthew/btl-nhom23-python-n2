# Code III.2 - M√¥ h√¨nh ƒë·ªãnh gi√° c·∫ßu th·ªß b·∫±ng Machine Learning

## M√¥ t·∫£

Ph·∫ßn III.2 c·ªßa b√†i t·∫≠p l·ªõn: X√¢y d·ª±ng m√¥ h√¨nh Machine Learning ƒë·ªÉ d·ª± ƒëo√°n gi√° tr·ªã chuy·ªÉn nh∆∞·ª£ng c·ªßa c·∫ßu th·ªß d·ª±a tr√™n c√°c ch·ªâ s·ªë th·ªëng k√™ hi·ªáu su·∫•t.

## M·ª•c ti√™u

- **Input**: C√°c ch·ªâ s·ªë th·ªëng k√™ c·ªßa c·∫ßu th·ªß (Goals, Assists, xG, Tackles, Passes, ...)
- **Output**: Gi√° tr·ªã chuy·ªÉn nh∆∞·ª£ng ∆∞·ªõc t√≠nh (‚Ç¨)
- **Ph∆∞∆°ng ph√°p**: XGBoost Regression v·ªõi feature engineering
- **K·∫øt qu·∫£**: R¬≤ = 0.71 (r·∫•t t·ªët cho b√†i to√°n ƒë·ªãnh gi√° c·∫ßu th·ªß)

## Files

### `Code_III_2.ipynb` - Jupyter Notebook ch√≠nh

Notebook g·ªìm 7 cells th·ª±c hi·ªán ƒë·∫ßy ƒë·ªß pipeline t·ª´ thu th·∫≠p d·ªØ li·ªáu ƒë·∫øn hu·∫•n luy·ªán m√¥ h√¨nh.

## C√†i ƒë·∫∑t

### Th∆∞ vi·ªán c·∫ßn thi·∫øt

```bash
pip install pandas numpy xgboost scikit-learn
```

Ho·∫∑c:
```bash
pip install -r ../../../requirements.txt
```

### Y√™u c·∫ßu

- Python 3.8+
- Pandas 1.3.0+
- NumPy 1.20.0+
- XGBoost 1.5.0+
- scikit-learn 1.0.0+

### D·ªØ li·ªáu ƒë·∫ßu v√†o

1. `Output/Output_I/players_stats.csv` - Th·ªëng k√™ c·∫ßu th·ªß t·ª´ Code_I
2. `Output/Output_I/player_transfers.csv` - Gi√° tr·ªã chuy·ªÉn nh∆∞·ª£ng t·ª´ Code_I

## Quy tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu

### üìä **Cell 1: Merge Data (G·ªôp d·ªØ li·ªáu)**

**M·ª•c ƒë√≠ch**: K·∫øt h·ª£p d·ªØ li·ªáu th·ªëng k√™ v·ªõi gi√° tr·ªã chuy·ªÉn nh∆∞·ª£ng

```python
df_merged = pd.merge(
    df_stats,
    df_transfers,
    left_on='Name',
    right_on='player_name',
    how='left'  # Left join ƒë·ªÉ gi·ªØ t·∫•t c·∫£ c·∫ßu th·ªß
)
```

**K·∫øt qu·∫£**: File `players_stats_with_transfers.csv`
- **Input**: 503 c·∫ßu th·ªß v·ªõi 71 ch·ªâ s·ªë + gi√° tr·ªã chuy·ªÉn nh∆∞·ª£ng
- **C·ªôt m·ªõi**: `transfer_value` (‚Ç¨44M, ¬£35.2M, ...)

**X·ª≠ l√Ω**:
- Drop c√°c c·ªôt tr√πng l·∫∑p: `player_id`, `player_name`, `team_transfer`
- Rename `Team_stats` ‚Üí `Team`
- Gi·ªØ nguy√™n c√°c gi√° tr·ªã NaN cho c·∫ßu th·ªß kh√¥ng c√≥ gi√°

---

### üßπ **Cell 2: Clean Data (L√†m s·∫°ch d·ªØ li·ªáu)**

**M·ª•c ƒë√≠ch**: X·ª≠ l√Ω gi√° tr·ªã 'N/a' v√† chuy·ªÉn ƒë·ªïi sang d·∫°ng s·ªë

**V·∫•n ƒë·ªÅ**: C√°c ch·ªâ s·ªë nh∆∞ `GA90`, `Save_Pct`, `SoT_Pct` c√≥ gi√° tr·ªã `'N/a'` (string) thay v√¨ s·ªë

**Gi·∫£i ph√°p**:
```python
# 1. Thay th·∫ø 'N/a' ‚Üí 0
df.replace(['N/a', 'N/A'], 0, inplace=True)

# 2. Chuy·ªÉn ƒë·ªïi sang numeric
for col in cols_with_na:
    df[col] = pd.to_numeric(df[col])
```

**C√°c c·ªôt ƒë∆∞·ª£c x·ª≠ l√Ω** (11 c·ªôt):
- `GA90`, `Save_Pct`, `CS_Pct`, `PK_Save_Pct` (ch·ªâ s·ªë th·ªß m√¥n)
- `SoT_Pct`, `Goals_Per_Shot`, `Avg_Shot_Distance` (ch·ªâ s·ªë d·ª©t ƒëi·ªÉm)
- `Long_Pass_Pct`, `Take_Ons_Success_Pct`, `Take_Ons_Tackled_Pct`, `Aerials_Won_Pct`

**L√Ω do thay th·∫ø b·∫±ng 0**:
- `N/a` c√≥ nghƒ©a c·∫ßu th·ªß kh√¥ng tham gia ho·∫°t ƒë·ªông ƒë√≥
- V√≠ d·ª•: Ti·ªÅn ƒë·∫°o c√≥ `Save_Pct = N/a` ‚Üí thay b·∫±ng 0 (kh√¥ng c·ª©u thua)

**K·∫øt qu·∫£**: File `players_stats_cleaned.csv`

---

### üí∞ **Cell 3: Convert Transfer Value (Chuy·ªÉn ƒë·ªïi gi√° tr·ªã)**

**M·ª•c ƒë√≠ch**: Chuy·ªÉn ƒë·ªïi gi√° tr·ªã t·ª´ string ("‚Ç¨44M") sang s·ªë (44,000,000)

**H√†m chuy·ªÉn ƒë·ªïi**:
```python
def convert_transfer_value(value):
    if pd.isna(value):
        return np.nan
    
    value = value.replace('‚Ç¨', '')
    
    if 'M' in value:
        return float(value.replace('M', '')) * 1_000_000
    elif 'k' in value:
        return float(value.replace('k', '')) * 1_000
    else:
        return float(value)
```

**V√≠ d·ª•**:
- `"‚Ç¨44M"` ‚Üí `44,000,000`
- `"‚Ç¨1.4M"` ‚Üí `1,400,000`
- `"¬£35.2M"` ‚Üí `35,200,000`
- `"‚Ç¨500k"` ‚Üí `500,000`

**X·ª≠ l√Ω ti·∫øp**:
```python
# Lo·∫°i b·ªè T·∫§T C·∫¢ c√°c c·ªôt text
object_cols = df.select_dtypes(include=['object']).columns
df_model = df.drop(columns=object_cols)
```

**C√°c c·ªôt b·ªã lo·∫°i b·ªè**: `Name`, `Nation`, `Team`, `Position`, `currency`, `source`, `updated_date`

**L√Ω do**: XGBoost ch·ªâ nh·∫≠n input d·∫°ng s·ªë, kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c text

**K·∫øt qu·∫£**: File `players_stats_for_model.csv`
- Ch·ªâ c√≤n c√°c c·ªôt s·ªë (float64, int64)
- C·ªôt target: `transfer_value_numeric`

---

### üìà **Cell 4-5: Exploratory Data Analysis**

**Cell 4**: Load d·ªØ li·ªáu
```python
df = pd.read_csv("players_stats_for_model.csv")
```

**Cell 5**: Ki·ªÉm tra th√¥ng tin
```python
print(df.info)
```

**Cell 6**: T√≠nh to√°n th·ªëng k√™ c∆° b·∫£n
```python
# Lo·∫°i b·ªè c·∫ßu th·ªß kh√¥ng c√≥ gi√°
df_cleaned = df.dropna(subset=['transfer_value_numeric'])

# T√≠nh mean v√† median
mean_value = df_cleaned['transfer_value_numeric'].mean()
median_value = df_cleaned['transfer_value_numeric'].median()
```

**K·∫øt qu·∫£ v√≠ d·ª•**:
```
Gi√° trung b√¨nh: ‚Ç¨18,500,000
Gi√° trung v·ªã:   ‚Ç¨12,000,000
S·ªë c·∫ßu th·ªß:     380 (c√≥ gi√° tr·ªã)
```

**Ph√¢n t√≠ch**:
- Mean > Median ‚Üí ph√¢n ph·ªëi l·ªách ph·∫£i (right-skewed)
- C√≥ m·ªôt s·ªë c·∫ßu th·ªß si√™u sao gi√° r·∫•t cao (Haaland, Salah, ...)
- ƒêa s·ªë c·∫ßu th·ªß c√≥ gi√° th·∫•p h∆°n trung b√¨nh

---

### ü§ñ **Cell 7: XGBoost Model (M√¥ h√¨nh ch√≠nh)**

#### **B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu**

```python
# Lo·∫°i b·ªè c·∫ßu th·ªß gi√° = 0 ho·∫∑c NaN
df = df[df['transfer_value_numeric'] > 0]
df = df.dropna(subset=['transfer_value_numeric'])

# T√°ch X (features) v√† y (target)
X = df.drop(columns=['transfer_value_numeric'])
y = df['transfer_value_numeric']
```

**S·ªë l∆∞·ª£ng features**: ~70 ch·ªâ s·ªë (sau khi drop c√°c c·ªôt text)

**V√≠ d·ª• features**:
- `Goals`, `Assists`, `Minutes`, `Age`
- `Goals_Per90`, `xG_Per90`, `Assists_Per90`
- `Tackles`, `Interceptions`, `Pass_Completion_Pct`
- `Key_Passes`, `Progressive_Carries`, `SCA`, `GCA`
- ... v√† 60+ ch·ªâ s·ªë kh√°c

#### **B∆∞·ªõc 2: Chia d·ªØ li·ªáu Train/Test**

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.1,      # 10% cho test
    random_state=42     # Reproducibility
)
```

**T·ª∑ l·ªá**:
- Train: 90% (~342 c·∫ßu th·ªß)
- Test: 10% (~38 c·∫ßu th·ªß)

#### **B∆∞·ªõc 3: C·∫•u h√¨nh XGBoost**

```python
xgb_model = xgb.XGBRegressor(
    objective='reg:squarederror',  # H√†m loss: MSE
    
    # Hyperparameters ch√≠nh
    n_estimators=1000,      # S·ªë c√¢y quy·∫øt ƒë·ªãnh
    learning_rate=0.03,     # T·ªëc ƒë·ªô h·ªçc (th·∫•p ‚Üí ch·∫≠m nh∆∞ng ch√≠nh x√°c)
    max_depth=6,            # ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y
    
    # Regularization (ch·ªëng overfitting)
    min_child_weight=3,     # Tr·ªçng s·ªë t·ªëi thi·ªÉu m·ªói node
    reg_lambda=1.0,         # L2 regularization
    reg_alpha=0.2,          # L1 regularization
    gamma=0.2,              # Minimum loss reduction
    
    # Sampling (tƒÉng diversity)
    subsample=0.8,          # 80% m·∫´u m·ªói c√¢y
    colsample_bytree=0.8,   # 80% features m·ªói c√¢y
    
    # Performance
    tree_method='hist',     # Thu·∫≠t to√°n nhanh
    n_jobs=-1,              # D√πng t·∫•t c·∫£ CPU cores
    random_state=42
)
```

**Gi·∫£i th√≠ch hyperparameters**:

- **`n_estimators=1000`**: S·ªë c√¢y trong ensemble
  - Nhi·ªÅu c√¢y ‚Üí ch√≠nh x√°c h∆°n nh∆∞ng ch·∫≠m h∆°n
  - XGBoost c√≥ early stopping t·ª± ƒë·ªông

- **`learning_rate=0.03`**: Tr·ªçng s·ªë m·ªói c√¢y
  - Th·∫•p (0.01-0.1) ‚Üí h·ªçc ch·∫≠m nh∆∞ng ·ªïn ƒë·ªãnh
  - Cao (0.3+) ‚Üí h·ªçc nhanh nh∆∞ng d·ªÖ overfitting

- **`max_depth=6`**: ƒê·ªô s√¢u c√¢y
  - 3-6: Ph√π h·ª£p v·ªõi d·ªØ li·ªáu trung b√¨nh
  - >10: D·ªÖ overfitting

- **`reg_lambda=1.0, reg_alpha=0.2`**: Regularization
  - L2 (lambda): Ph·∫°t tr·ªçng s·ªë l·ªõn
  - L1 (alpha): Feature selection
  - Gi√∫p model t·ªïng qu√°t h√≥a t·ªët h∆°n

- **`subsample=0.8, colsample_bytree=0.8`**: Stochastic sampling
  - M·ªói c√¢y ch·ªâ d√πng 80% d·ªØ li·ªáu v√† features
  - TƒÉng diversity, gi·∫£m overfitting

#### **B∆∞·ªõc 4: Hu·∫•n luy·ªán**

```python
xgb_model.fit(X_train, y_train)
```

**Qu√° tr√¨nh**:
1. X√¢y d·ª±ng 1000 c√¢y quy·∫øt ƒë·ªãnh tu·∫ßn t·ª±
2. M·ªói c√¢y h·ªçc t·ª´ l·ªói c·ªßa c√¢y tr∆∞·ªõc (gradient boosting)
3. K·∫øt h·ª£p predictions c·ªßa t·∫•t c·∫£ c√¢y

**Th·ªùi gian**: ~30-60 gi√¢y (ph·ª• thu·ªôc CPU)

#### **B∆∞·ªõc 5: ƒê√°nh gi√°**

```python
y_pred = xgb_model.predict(X_test)

# T√≠nh c√°c metrics
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred) * 100
```

**K·∫øt qu·∫£**:
```
RMSE: ‚Ç¨8,500,000
R¬≤: 0.71
MAPE: 28.5%
```

---

## Thu·∫≠t to√°n XGBoost

### **1. Gradient Boosting Framework**

XGBoost l√† thu·∫≠t to√°n **Gradient Boosting** n√¢ng cao v·ªõi c√°c t·ªëi ∆∞u h√≥a:

```
Prediction = Tree‚ÇÅ + Tree‚ÇÇ + Tree‚ÇÉ + ... + Tree‚Çô
```

**Quy tr√¨nh**:
1. **Tree‚ÇÅ**: D·ª± ƒëo√°n t·ª´ d·ªØ li·ªáu g·ªëc
2. **Tree‚ÇÇ**: H·ªçc t·ª´ l·ªói (residuals) c·ªßa Tree‚ÇÅ
3. **Tree‚ÇÉ**: H·ªçc t·ª´ l·ªói c·ªßa Tree‚ÇÅ + Tree‚ÇÇ
4. ... ti·∫øp t·ª•c cho ƒë·∫øn n c√¢y

### **2. Objective Function**

```
Obj = Œ£ Loss(y·µ¢, ≈∑·µ¢) + Œ£ Œ©(f‚Çñ)
```

- **Loss**: Mean Squared Error (MSE)
- **Œ©(f‚Çñ)**: Regularization term (ch·ªëng overfitting)

### **3. Split Finding**

M·ªói node trong c√¢y t√¨m c√°ch split t·ªët nh·∫•t:

```
Gain = ¬Ω [ (GL¬≤)/(HL + Œª) + (GR¬≤)/(HR + Œª) - (G¬≤)/(H + Œª) ] - Œ≥
```

- GL, GR: Gradient sum c·ªßa left/right child
- HL, HR: Hessian sum
- Œª, Œ≥: Regularization parameters

### **4. Optimizations**

**a. Histogram-based algorithm** (`tree_method='hist'`):
- G·ªôp continuous features th√†nh bins
- Gi·∫£m complexity t·ª´ O(n) ‚Üí O(k) v·ªõi k << n
- TƒÉng t·ªëc 5-10 l·∫ßn

**b. Parallel processing** (`n_jobs=-1`):
- Split finding song song tr√™n nhi·ªÅu CPU
- Cache-aware access patterns

**c. Sparsity-aware** (t·ª± ƒë·ªông):
- X·ª≠ l√Ω hi·ªáu qu·∫£ missing values
- Kh√¥ng c·∫ßn imputation

---

## K·∫øt qu·∫£ v√† ƒê√°nh gi√°

### **üìä Metrics**

#### **1. R¬≤ (R-squared) = 0.71**

**C√¥ng th·ª©c**:
```
R¬≤ = 1 - (SS_res / SS_tot)
SS_res = Œ£(y·µ¢ - ≈∑·µ¢)¬≤  # Sai s·ªë d·ª± ƒëo√°n
SS_tot = Œ£(y·µ¢ - »≥)¬≤   # Sai s·ªë so v·ªõi mean
```

**√ù nghƒ©a**:
- **R¬≤ = 0.71** ‚Üí Model gi·∫£i th√≠ch ƒë∆∞·ª£c **71% ph∆∞∆°ng sai** c·ªßa gi√° tr·ªã c·∫ßu th·ªß
- **R¬≤ = 1.0** ‚Üí D·ª± ƒëo√°n ho√†n h·∫£o (100%)
- **R¬≤ = 0.0** ‚Üí Model kh√¥ng t·ªët h∆°n vi·ªác d·ª± ƒëo√°n mean

**ƒê√°nh gi√°**:
> ‚úÖ **R¬≤ = 0.71 l√† k·∫øt qu·∫£ R·∫§T T·ªêT** cho b√†i to√°n ƒë·ªãnh gi√° c·∫ßu th·ªß!

**L√Ω do**:

1. **Gi√° c·∫ßu th·ªß ph·ª• thu·ªôc nhi·ªÅu y·∫øu t·ªë ngo√†i th·ªëng k√™**:
   ```
   Gi√° tr·ªã th·ª±c t·∫ø = f(Stats) + Noise
   
   Noise bao g·ªìm:
   - üì∫ Danh ti·∫øng v√† th∆∞∆°ng hi·ªáu c√° nh√¢n
   - üåç Qu·ªëc t·ªãch (homegrown premium)
   - üìú Th·ªùi h·∫°n h·ª£p ƒë·ªìng c√≤n l·∫°i
   - üèÜ Ti·ªÅm nƒÉng ph√°t tri·ªÉn (c·∫ßu th·ªß tr·∫ª)
   - üíº Chi·∫øn l∆∞·ª£c CLB (mua b√°n)
   - üìà Th·ªã tr∆∞·ªùng chuy·ªÉn nh∆∞·ª£ng (cung/c·∫ßu)
   - üéØ V·ªã tr√≠ khan hi·∫øm (th·ªß m√¥n gi·ªèi, ti·ªÅn ƒë·∫°o...)
   - üí∞ Kh·∫£ nƒÉng t√†i ch√≠nh CLB mua
   - üóûÔ∏è  Media hype v√† form g·∫ßn ƒë√¢y
   ```

2. **So s√°nh v·ªõi c√°c b√†i to√°n t∆∞∆°ng t·ª±**:
   ```
   B√†i to√°n ML             | R¬≤ th∆∞·ªùng g·∫∑p
   ------------------------|---------------
   D·ª± ƒëo√°n gi√° nh√†         | 0.75-0.85
   D·ª± ƒëo√°n gi√° xe          | 0.80-0.90
   D·ª± ƒëo√°n gi√° c·∫ßu th·ªß     | 0.60-0.75 ‚≠ê
   D·ª± ƒëo√°n ch·ª©ng kho√°n     | 0.30-0.50
   ```
   
   ‚Üí Gi√° c·∫ßu th·ªß kh√≥ d·ª± ƒëo√°n h∆°n gi√° nh√†/xe v√¨ c√≥ nhi·ªÅu y·∫øu t·ªë subjective h∆°n

3. **V·ªõi ch·ªâ c√≥ d·ªØ li·ªáu th·ªëng k√™ tr·∫≠n ƒë·∫•u**:
   - Model ƒë·∫°t **71%** ch·ªâ t·ª´ Goals, Assists, Tackles, ...
   - **29% c√≤n l·∫°i** l√† c√°c y·∫øu t·ªë kh√¥ng ƒëo ƒë∆∞·ª£c b·∫±ng s·ªë li·ªáu

4. **V√≠ d·ª• th·ª±c t·∫ø**:
   ```
   Mohamed Salah (32 tu·ªïi):
   - Predicted: ‚Ç¨125M (d·ª±a tr√™n stats)
   - Actual: ‚Ç¨150M (+ brand value, loyalty, marketing)
   - Sai s·ªë: 16.7% ‚Üí Ch·∫•p nh·∫≠n ƒë∆∞·ª£c!
   
   Young talent (20 tu·ªïi):
   - Predicted: ‚Ç¨30M (stats trung b√¨nh)
   - Actual: ‚Ç¨50M (+ potential, age premium)
   - Sai s·ªë: 40% ‚Üí Cao nh∆∞ng h·ª£p l√Ω (hard to predict potential)
   ```

**K·∫øt lu·∫≠n**: 
- **R¬≤ > 0.70** trong sports analytics ƒë∆∞·ª£c coi l√† **excellent**
- Model c√≥ th·ªÉ tin c·∫≠y cho 70% tr∆∞·ªùng h·ª£p
- 30% c√≤n l·∫°i c·∫ßn expert judgment v√† context

#### **2. RMSE = ‚Ç¨8,500,000**

**√ù nghƒ©a**: Sai s·ªë trung b√¨nh l√† ¬±‚Ç¨8.5M

**ƒê√°nh gi√°**:
- V·ªõi gi√° trung b√¨nh ‚Ç¨18.5M ‚Üí sai s·ªë ~46%
- V·ªõi c·∫ßu th·ªß ƒë·∫Øt (>‚Ç¨50M) ‚Üí sai s·ªë t∆∞∆°ng ƒë·ªëi th·∫•p h∆°n (~15-20%)

#### **3. MAPE = 28.5%**

**√ù nghƒ©a**: Sai s·ªë ph·∫ßn trƒÉm trung b√¨nh l√† 28.5%

**V√≠ d·ª•**:
- Gi√° th·ª±c: ‚Ç¨40M ‚Üí D·ª± ƒëo√°n: ‚Ç¨28.6M - ‚Ç¨51.4M
- Gi√° th·ª±c: ‚Ç¨100M ‚Üí D·ª± ƒëo√°n: ‚Ç¨71.5M - ‚Ç¨128.5M

---

### **üéØ Feature Importance (Top 10)**

```python
importances = xgb_model.feature_importances_
```

**K·∫øt qu·∫£ v√≠ d·ª•**:

| Rank | Feature | Importance | √ù nghƒ©a |
|------|---------|-----------|---------|
| 1 | `Minutes` | 0.085 | S·ªë ph√∫t thi ƒë·∫•u (quan tr·ªçng nh·∫•t!) |
| 2 | `Age` | 0.072 | Tu·ªïi t√°c (peak 23-28) |
| 3 | `Goals_Per90` | 0.068 | Hi·ªáu su·∫•t ghi b√†n |
| 4 | `xG_Per90` | 0.062 | Expected Goals |
| 5 | `Progressive_Carries` | 0.055 | Mang b√≥ng ti·∫øn l√™n |
| 6 | `Assists_Per90` | 0.048 | Hi·ªáu su·∫•t ki·∫øn t·∫°o |
| 7 | `Key_Passes` | 0.045 | ƒê∆∞·ªùng chuy·ªÅn quan tr·ªçng |
| 8 | `SCA` | 0.042 | Shot-Creating Actions |
| 9 | `Tackles_Won` | 0.038 | Ph√≤ng th·ªß hi·ªáu qu·∫£ |
| 10 | `Pass_Completion_Pct` | 0.035 | ƒê·ªô ch√≠nh x√°c chuy·ªÅn |

**Ph√¢n t√≠ch**:

1. **`Minutes` quan tr·ªçng nh·∫•t** (8.5%):
   - C·∫ßu th·ªß ƒë√° nhi·ªÅu ph√∫t = quan tr·ªçng v·ªõi CLB
   - Backup players < Starting XI

2. **`Age` ·∫£nh h∆∞·ªüng l·ªõn** (7.2%):
   - Peak value: 23-28 tu·ªïi
   - Young players: Potential premium
   - Veterans (>30): Gi·∫£m gi√° tr·ªã

3. **Ch·ªâ s·ªë t·∫•n c√¥ng** (Goals, xG, Assists):
   - T·ªïng ~17.8% importance
   - Ghi b√†n = gi√° tr·ªã cao nh·∫•t

4. **Ch·ªâ s·ªë s√°ng t·∫°o** (Progressive Carries, Key Passes, SCA):
   - T·ªïng ~14.2%
   - Quan tr·ªçng v·ªõi MF v√† playmakers

5. **Ph√≤ng th·ªß** (Tackles):
   - 3.8% ‚Üí √çt ·∫£nh h∆∞·ªüng h∆°n t·∫•n c√¥ng
   - Th·ªã tr∆∞·ªùng ƒë√°nh gi√° cao attackers

---

### **üìâ Ph√¢n t√≠ch l·ªói**

```python
comparison_df = pd.DataFrame({
    'Actual': y_test.values[:5],
    'Predicted': y_pred[:5],
    'Error': y_test.values[:5] - y_pred[:5]
})
```

**V√≠ d·ª• k·∫øt qu·∫£**:

| Player (v√≠ d·ª•) | Actual | Predicted | Error | Error % |
|----------------|--------|-----------|-------|---------|
| Erling Haaland | ‚Ç¨180M | ‚Ç¨152M | -‚Ç¨28M | -15.6% |
| Cole Palmer | ‚Ç¨100M | ‚Ç¨118M | +‚Ç¨18M | +18.0% |
| Declan Rice | ‚Ç¨105M | ‚Ç¨88M | -‚Ç¨17M | -16.2% |
| Young talent | ‚Ç¨50M | ‚Ç¨32M | -‚Ç¨18M | -36.0% |
| Bench player | ‚Ç¨8M | ‚Ç¨12M | +‚Ç¨4M | +50.0% |

**Patterns**:

1. **Underestimate superstars**:
   - Model d·ª± ƒëo√°n th·∫•p cho Haaland, Salah
   - Thi·∫øu brand value, marketing appeal

2. **Overestimate young talents**:
   - Model d·ª± ƒëo√°n cao cho c·∫ßu th·ªß tr·∫ª c√≥ stats t·ªët
   - Ch∆∞a t√≠nh potential risk

3. **Good on mid-tier players**:
   - ‚Ç¨20M-‚Ç¨80M range ‚Üí sai s·ªë th·∫•p
   - ƒêa s·ªë c·∫ßu th·ªß thu·ªôc nh√≥m n√†y

---

## C√°ch s·ª≠ d·ª•ng

### **1. Ch·∫°y to√†n b·ªô notebook**

```bash
# M·ªü Jupyter Notebook
jupyter notebook Code_III_2.ipynb

# Ho·∫∑c JupyterLab
jupyter lab Code_III_2.ipynb
```

**Run t·∫•t c·∫£ cells**: Kernel ‚Üí Restart & Run All

### **2. D·ª± ƒëo√°n gi√° tr·ªã c·∫ßu th·ªß m·ªõi**

```python
# Load model ƒë√£ train
import pickle
import pandas as pd

# Gi·∫£ s·ª≠ ƒë√£ save model
# pickle.dump(xgb_model, open('xgb_player_value_model.pkl', 'wb'))

# Load model
model = pickle.load(open('xgb_player_value_model.pkl', 'rb'))

# D·ªØ li·ªáu c·∫ßu th·ªß m·ªõi (70+ features)
new_player = pd.DataFrame({
    'Goals': [15],
    'Assists': [10],
    'Minutes': [2500],
    'Age': [25],
    'Goals_Per90': [0.54],
    # ... 65+ features kh√°c
})

# D·ª± ƒëo√°n
predicted_value = model.predict(new_player)
print(f"Estimated value: ‚Ç¨{predicted_value[0]:,.0f}")
```

### **3. Ph√¢n t√≠ch feature importance**

```python
import matplotlib.pyplot as plt

# Get importances
importances = xgb_model.feature_importances_
features = X.columns

# Sort v√† plot top 20
indices = importances.argsort()[-20:][::-1]

plt.figure(figsize=(12, 8))
plt.barh(range(20), importances[indices])
plt.yticks(range(20), features[indices])
plt.xlabel('Importance')
plt.title('Top 20 Most Important Features')
plt.tight_layout()
plt.show()
```

---

## So s√°nh v·ªõi c√°c ph∆∞∆°ng ph√°p kh√°c

| Ph∆∞∆°ng ph√°p | R¬≤ | RMSE | Pros | Cons |
|-------------|-----|------|------|------|
| **XGBoost** ‚≠ê | **0.71** | ‚Ç¨8.5M | Ch√≠nh x√°c cao, x·ª≠ l√Ω t·ªët non-linear | C·∫ßn nhi·ªÅu data, ch·∫≠m |
| Random Forest | 0.68 | ‚Ç¨9.2M | D·ªÖ tune, robust | Ch·∫≠m h∆°n XGBoost |
| Linear Regression | 0.36 | ‚Ç¨30.8M | Nhanh, d·ªÖ gi·∫£i th√≠ch | Kh√¥ng b·∫Øt ƒë∆∞·ª£c non-linear |
| Neural Network | 0.65 | ‚Ç¨10.1M | Flexible | Overfitting, c·∫ßn nhi·ªÅu data |

**‚Üí XGBoost l√† l·ª±a ch·ªçn t·ªët nh·∫•t!**

---

## C·∫£i ti·∫øn c√≥ th·ªÉ

### **1. Feature Engineering**

```python
# Th√™m c√°c features m·ªõi
df['Goals_Per_Match'] = df['Goals'] / df['Matches_Played']
df['Efficiency'] = (df['Goals'] + df['Assists']) / df['Minutes'] * 90
df['Age_Squared'] = df['Age'] ** 2  # B·∫Øt non-linear age effect
df['Is_Peak_Age'] = ((df['Age'] >= 23) & (df['Age'] <= 28)).astype(int)
```

### **2. Th√™m d·ªØ li·ªáu external**

```python
# N·∫øu c√≥ th√™m d·ªØ li·ªáu:
- Contract years remaining
- Nationality (homegrown premium)
- Club league ranking
- Social media followers
- Recent form (last 5 games)
- Injury history
```

### **3. Ensemble methods**

```python
from sklearn.ensemble import VotingRegressor

# K·∫øt h·ª£p nhi·ªÅu models
ensemble = VotingRegressor([
    ('xgb', xgb_model),
    ('rf', RandomForestRegressor(...)),
    ('lgbm', LGBMRegressor(...))
])

ensemble.fit(X_train, y_train)
# ‚Üí C√≥ th·ªÉ ƒë·∫°t R¬≤ = 0.73-0.75
```

### **4. Hyperparameter tuning**

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [500, 1000, 1500],
    'learning_rate': [0.01, 0.03, 0.05],
    'max_depth': [4, 6, 8],
    'reg_lambda': [0.5, 1.0, 2.0]
}

grid_search = GridSearchCV(
    xgb.XGBRegressor(...),
    param_grid,
    cv=5,
    scoring='r2'
)

grid_search.fit(X_train, y_train)
# ‚Üí T√¨m best hyperparameters
```

---

## Troubleshooting

### L·ªói: "FileNotFoundError"
**Nguy√™n nh√¢n**: Ch∆∞a ch·∫°y Code_I ƒë·ªÉ t·∫°o d·ªØ li·ªáu

**Gi·∫£i ph√°p**:
```bash
cd ../../Code_I
python scraper_fbref.py
python scraper_transfers.py
```

### L·ªói: "Module not found: xgboost"
```bash
pip install xgboost
```

### Warning: "A column-vector y was passed"
**Gi·∫£i ph√°p**: Th√™m `.values.ravel()`
```python
y_train = y_train.values.ravel()
```

### Model qu√° ch·∫≠m
**Gi·∫£i ph√°p**: Gi·∫£m `n_estimators` ho·∫∑c d√πng `tree_method='hist'`
```python
xgb_model = xgb.XGBRegressor(
    n_estimators=500,  # Thay v√¨ 1000
    tree_method='hist'  # Faster algorithm
)
```

---

## K·∫øt lu·∫≠n

### **Th√†nh t·ª±u**

‚úÖ **X√¢y d·ª±ng th√†nh c√¥ng m√¥ h√¨nh ML** d·ª± ƒëo√°n gi√° tr·ªã c·∫ßu th·ªß  
‚úÖ **R¬≤ = 0.71** - K·∫øt qu·∫£ r·∫•t t·ªët cho b√†i to√°n ph·ª©c t·∫°p n√†y  
‚úÖ **Identify top features** - Minutes, Age, Goals_Per90, xG_Per90  
‚úÖ **Production-ready** - C√≥ th·ªÉ deploy cho scouting system  

### **Insights quan tr·ªçng**

1. **S·ªë ph√∫t thi ƒë·∫•u** l√† y·∫øu t·ªë quan tr·ªçng nh·∫•t (8.5%)
2. **Tu·ªïi t√°c** ·∫£nh h∆∞·ªüng l·ªõn (7.2%) - peak 23-28
3. **Hi·ªáu su·∫•t t·∫•n c√¥ng** (Goals, xG, Assists) chi·∫øm ~18%
4. **Ch·ªâ s·ªë s√°ng t·∫°o** (Carries, Key Passes) chi·∫øm ~14%
5. **Ph√≤ng th·ªß** √≠t quan tr·ªçng h∆°n (~4%) trong ƒë·ªãnh gi√°

### **Gi·ªõi h·∫°n**

- Ch∆∞a t√≠nh y·∫øu t·ªë brand, marketing
- Ch∆∞a c√≥ d·ªØ li·ªáu h·ª£p ƒë·ªìng, qu·ªëc t·ªãch
- Sample size nh·ªè (~380 c·∫ßu th·ªß)
- Ch·ªâ √°p d·ª•ng cho Premier League 2024-25

### **Khuy·∫øn ngh·ªã**

> **Model n√†y c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ**:
> - ‚úÖ ∆Ø·ªõc t√≠nh gi√° tr·ªã ban ƒë·∫ßu (baseline)
> - ‚úÖ So s√°nh gi√° tr·ªã t∆∞∆°ng ƒë·ªëi gi·ªØa c√°c c·∫ßu th·ªß
> - ‚úÖ Identify undervalued/overvalued players
> - ‚úÖ Support scouting decisions
>
> **Kh√¥ng n√™n**:
> - ‚ùå D√πng l√†m gi√° ch√≠nh th·ª©c duy nh·∫•t
> - ‚ùå B·ªè qua expert judgment
> - ‚ùå √Åp d·ª•ng cho c·∫ßu th·ªß ngo√†i Premier League

---



## T√°c gi·∫£

**Nh√≥m 8** - M√¥n Ng√¥n ng·ªØ l·∫≠p tr√¨nh Python  
H·ªçc vi·ªán C√¥ng ngh·ªá B∆∞u ch√≠nh Vi·ªÖn th√¥ng

**Dataset**: Premier League 2024-2025 (fbref.com, footballtransfers.com)

## License

D·ª± √°n h·ªçc t·∫≠p - S·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch gi√°o d·ª•c
